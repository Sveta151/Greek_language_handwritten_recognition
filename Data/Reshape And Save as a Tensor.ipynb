{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.1"},"colab":{"name":"Reshape And Save as a Tensor.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"47ca89a5"},"source":["import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import os"],"id":"47ca89a5","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a6687bc3"},"source":["# I have Google Drive app for my laptop and it mirrors the folder in cloud. \n","# I am running this noutbook in my laptop and the changes are synchronized.\n","images_folder = 'Cleansed alphabet data/new/'\n","new_images_folder = 'Cleansed alphabet data/reshaped/'"],"id":"a6687bc3","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"edc00c48"},"source":["def transform_image(image, channel = 3):\n","    w, h = image.size\n","    \n","    if w == h:\n","        data = np.asanyarray(image, 'int32')\n","        if channels > 1:\n","            data = np.mean(data, axis=2)\n","        image = Image.fromarray(data.astype('uint8'), 'L')\n","        return image.resize((64, 64), Image.ANTIALIAS)\n","    \n","    d = np.random.randint(0, np.abs(w - h)//3 + 1)\n","\n","    if w > h:\n","        k = d\n","        m = (w-h)-k\n","\n","        if channel == 1:\n","            data = np.ones((w, w))*255\n","            data[k:-m,:] = np.asanyarray(image, 'int32')\n","            image = Image.fromarray(data.astype('uint8'), 'L')\n","        else :\n","            data = np.ones((w, w, channels))*255\n","            data[k:-m,:,:] = np.asanyarray(image, 'int32')\n","            image = Image.fromarray(data.astype('uint8'), 'L')            \n","\n","    elif(h > w):\n","        k = d\n","        m = (h - w) - k\n","\n","        if channel == 1:\n","            data = np.ones((h, h)) * 255\n","            data[:,k:-m] = np.asanyarray(image, 'int32')\n","            image = Image.fromarray(data.astype('uint8'), 'L')\n","        else :\n","            data = np.ones((h, h, channels)) * 255\n","            data[:,k:-m, :] = np.asanyarray(image, 'int32')\n","            image = Image.fromarray(data.astype('uint8'), 'L')\n","\n","    image.resize((64, 64), Image.ANTIALIAS)\n","    return image\n","    "],"id":"edc00c48","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"20a95c3d","outputId":"90e04923-a3c5-4c04-b92a-0a02e201cc59"},"source":["if not os.path.isdir(new_images_folder):\n","    os.mkdir(new_images_folder)\n","folders = os.listdir(images_folder)\n","\n","for folder in folders:\n","    print(images_folder + folder + '/')\n","    \n","    if not os.path.isdir(images_folder + folder + '/'):\n","        continue\n","    image_names = os.listdir(images_folder + folder + '/')\n","    \n","    for name in image_names:\n","        image = Image.open(images_folder + folder + '/' + name)\n","        channels = len(image.getbands())\n","        image = transform_image(image, channels)\n","        \n","        if not os.path.isdir(new_images_folder + folder + '/'):\n","            os.mkdir(new_images_folder + folder + '/')\n","        image.save(new_images_folder + folder + '/' + name)"],"id":"20a95c3d","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Cleansed alphabet data/new/New-Untitled-6/\n"]}]},{"cell_type":"code","metadata":{"id":"dc60ac34"},"source":["folders_dir = 'Cleansed alphabet data/labelled/'\n","dest = 'Cleansed alphabet data/done/'\n","\n","folders = os.listdir(folders_dir)\n","\n","i = 48\n","\n","labels = []\n","\n","for folder in folders:\n","    \n","    if os.path.isfile(folder):\n","        continue\n","    \n","    images = os.listdir(folders_dir + folder + '/')\n","    \n","    for image in images:\n","        labels.append(image.split('.')[0])\n","        os.rename(folders_dir + folder + '/' + image, dest + 'pic_' + str(i) + '.png')\n","        i += 1\n","\n","a = labels\n","\n","file = open(dest + 'labels.txt', 'w')\n","\n","for item in a:\n","    file.write(item + '\\n')\n","\n","file.close()"],"id":"dc60ac34","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c7dac606"},"source":["import torch\n","from torchvision import transforms\n","import pandas as pd"],"id":"c7dac606","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"16d0d7b7"},"source":["done_images_folder = 'Cleansed alphabet data/done/'\n","\n","tensors = []\n","for i in range(0, 2000):\n","    image_path = done_images_folder + 'pic_{}.png'.format(i)\n","    \n","    if not os.path.isfile(image_path):\n","        break\n","    \n","    image = Image.open(image_path)\n","    \n","    channels = len(image.getbands())\n","    \n","    tensor = transforms.PILToTensor()(image)\n","    tensors.append(tensor)\n","\n","all_images = torch.stack(tensors)\n","\n"],"id":"16d0d7b7","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bdc14823","outputId":"1e9ea34e-b60d-4065-ea81-23a99eab274d"},"source":["data = torch.mean(all_images.float(), axis=1)\n","\n","data.shape"],"id":"bdc14823","execution_count":null,"outputs":[{"data":{"text/plain":["torch.Size([1094, 64, 64])"]},"execution_count":109,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"4b22aa58"},"source":["torch.save(data, done_images_folder + 'train_data.pt')"],"id":"4b22aa58","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ea455bb"},"source":["df = pd.read_csv(done_images_folder + 'labels.txt', header=None)\n","\n","series = pd.Series.map(df[0], lambda x : trans_from_labels[x])\n","\n","labels = torch.from_numpy(np.array(series))\n","torch.save(labels, done_images_folder + 'train_labels.pt')"],"id":"8ea455bb","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1451f01a"},"source":["trans = {\n","'A':0, 'B':1, 'G':2, 'D':3, 'E':4,  'Z':5,\n","'H':6, 'C':7, 'I':8, 'K':9, 'L':10, 'M':11,\n","'N':12,'Q':13,'O':14,'P':15,'R':16, 'S':17,\n","'T':18,'U':19,'F':20,'X':21,'V':22, 'W':23,\n","'a':24,'b':25,'g':26,'d':27,'e':28, 'z':29,\n","'h':30,'c':31,'i':32,'k':33,'l':34, 'm':35,\n","'n':36,'q':37,'o':38,'p':39,'r':40, 's':41,\n","'t':42,'u':43,'f':44,'x':45,'v':46, 'w':47\n","}\n","\n","trans_from_labels = {\n","'Alpha_':0, 'Beta_':1, 'Gamma_':2, 'Delta_':3, 'Epsilon_':4,  'Zeta_':5,\n","'Eta_':6, 'Theta_':7, 'Iota_':8, 'Kappa_':9, 'Lambda_':10, 'Mu_':11,\n","'Nu_':12,'Xi_':13,'Omicron_':14,'Pi_':15,'Rho_':16, 'Sigma_':17,\n","'Tau_':18,'Upsilon_':19,'Phi_':20,'Chi_':21,'Psi_':22, 'Omega_':23,\n","'alpha':24,'beta':25,'gamma':26,'delta':27,'epsilon':28, 'zeta':29,\n","'eta':30,'theta':31,'iota':32,'kappa':33,'lambda':34, 'mu':35,\n","'nu':36,'xi':37,'omicron':38,'pi':39,'rho':40, 'sigma':41, 'sigma__':41,\n","'tau':42,'upsilon':43,'phi':44,'chi':45,'psi':46, 'omega':47\n","}"],"id":"1451f01a","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"933b02dc","outputId":"2f258e57-9807-4efa-b021-185d4059c9f5"},"source":["print(trans_from_labels.keys())"],"id":"933b02dc","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["dict_keys(['Alpha_', 'Beta_', 'Gamma_', 'Delta_', 'Epsilon_', 'Zeta_', 'Eta_', 'Theta_', 'Iota_', 'Kappa_', 'Lambda_', 'Mu_', 'Nu_', 'Xi_', 'Omicron_', 'Pi_', 'Rho_', 'Sigma_', 'Tau_', 'Upsilon_', 'Phi_', 'Chi_', 'Psi_', 'Omega_', 'alpha', 'beta', 'gamma', 'delta', 'epsilon', 'zeta', 'eta', 'theta', 'iota', 'kappa', 'lambda', 'mu', 'nu', 'xi', 'omicron', 'pi', 'rho', 'sigma', 'sigma__', 'tau', 'upsilon', 'phi', 'chi', 'psi', 'omega'])\n"]}]},{"cell_type":"code","metadata":{"id":"e01d64a6"},"source":["data = torch.load('cropped_letters_labels/train_data.pt')\n","\n","x = torch.mean(data.float(), axis=1)\n","\n","torch.save(x, 'cropped_letters_labels/train_data.pt')"],"id":"e01d64a6","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"09b2f8b6","outputId":"8be87a4a-d1e4-42ab-8771-b4a4bc5cf48e"},"source":["data = torch.load('cropped_letters_labels/train_data.pt')\n","\n","print(data.shape)"],"id":"09b2f8b6","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([462, 64, 64])\n"]}]},{"cell_type":"code","metadata":{"id":"bfd58b7a"},"source":[""],"id":"bfd58b7a","execution_count":null,"outputs":[]}]}